{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7a1bb1-0c21-4a12-b239-9b84b33e18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution, edit_model\n",
    "\n",
    "from contextlib import redirect_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7241a297-f299-4712-9a8a-23d77bbd39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EleutherAI/gpt-j-6B\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "\n",
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=True).to(\n",
    "        \"cuda\"\n",
    "    ),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1daf74-3622-45d5-9dab-1645dc7321f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.pad_token = tok.eos_token\n",
    "ALG_NAME = \"ROME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "528c7ad6-14da-4914-b174-f3f9b96dba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_gen_prompts(prompt):\n",
    "    p = (\n",
    "        prompt\n",
    "        .replace(\"recently entered\", \"entered\")\n",
    "        .replace(\" restaurants\", \" sights\") # not about tense, should be its own thing\n",
    "    )\n",
    "    \n",
    "    return(p)\n",
    "\n",
    "\n",
    "def tense_to_past(prompt):\n",
    "    p = (\n",
    "        prompt\n",
    "        .replace(\" is\", \" was\")\n",
    "        .replace(\" speak\", \" spoke\")\n",
    "        .replace(\" carries\", \" carried\")\n",
    "        .replace(\" produces\", \" produced\")\n",
    "        .replace(\" include\", \" included\")\n",
    "        .replace(\" works\", \" worked\")\n",
    "        .replace(\" has\", \" had\")\n",
    "        .replace(\" lives\", \" lived\")\n",
    "        .replace(\" sells\", \" sold\")\n",
    "        .replace(\" owns\", \" owned\")\n",
    "    )\n",
    "\n",
    "    return(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f389390-0272-4991-8ddf-f4609b7caa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193  rewrites to test\n"
     ]
    }
   ],
   "source": [
    "chosen = pd.read_csv(\"counterfact/selected-items.csv\")\n",
    "json_data = [] # your list with json objects (dicts)\n",
    "\n",
    "with open('counterfact/counterfact.json') as json_file:\n",
    "   json_data = json.load(json_file)\n",
    "   \n",
    "subjects = list(set([x['requested_rewrite']['subject'] for x in json_data]))\n",
    "relations = list(set([x['requested_rewrite']['relation_id'] for x in json_data]))\n",
    "\n",
    "print(len(chosen), \" rewrites to test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c4d2621-e880-4195-aaba-42b351310994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [50:21<00:00, 15.65s/it]\n"
     ]
    }
   ],
   "source": [
    "gen_list = []\n",
    "\n",
    "for i in tqdm(range(len(chosen))):    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for k, v in orig_weights.items():\n",
    "                nethook.get_parameter(model, k)[...] = v\n",
    "        # print(\"Original model restored\")\n",
    "    except NameError as e:\n",
    "        None\n",
    "        # print(f\"No model weights to restore: {e}\")\n",
    "    \n",
    "    c = chosen.loc[i]\n",
    "    item = [x for x in json_data if x[\"case_id\"]==c.case_id][0]\n",
    "\n",
    "    rewrites = [item[\"requested_rewrite\"]]\n",
    "    gen_prompts = [fix_gen_prompts(x) for x in item[\"generation_prompts\"]] if c.past==0 else [tense_to_past(fix_gen_prompts(x)) for x in item[\"generation_prompts\"]]\n",
    "    \n",
    "    with redirect_stdout(None):\n",
    "        model_new, orig_weights = edit_model(\n",
    "            model, tok, rewrites, alg_name=ALG_NAME\n",
    "        )l\n",
    "    \n",
    "    generations = generate_fast(model_new, tok, gen_prompts, max_out_len = 100)\n",
    "    gen_list.append(generations)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b6a368-74d8-4df1-88bf-13edda0a69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dict = dict()\n",
    "for i in range(len(chosen)):\n",
    "    c = chosen.loc[i]\n",
    "    gen_dict[int(c.case_id)] = gen_list[i]\n",
    "    \n",
    "with open('counterfact/gens-gpt-j-6.json', 'w') as f:\n",
    "  json.dump(gen_dict, f, ensure_ascii=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c6d93c-83a9-47f8-8f41-283300ef65c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-pip",
   "language": "python",
   "name": "pytorch-pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
