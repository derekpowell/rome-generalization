{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7a1bb1-0c21-4a12-b239-9b84b33e18d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmpowell/.conda/envs/pytorch-gpu-2.0/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution, edit_model\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e23099a-5018-430d-be27-1029401ea472",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"databricks/dolly-v1-6b\" # MODEL_NAME = \"databricks/dolly-v1-6b\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B or databricks/dolly-v1-6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7241a297-f299-4712-9a8a-23d77bbd39cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 763/763 [00:00<00:00, 348kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 3.65MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.78MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.14M/2.14M [00:00<00:00, 36.1MB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|██████████| 4.40k/4.40k [00:00<00:00, 11.0MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 567/567 [00:00<00:00, 1.78MB/s]\n"
     ]
    }
   ],
   "source": [
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=True).to(\n",
    "        \"cuda\"\n",
    "    ),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a7e3823-402a-412f-8626-c9882bdebc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/gpt-j-6B\n"
     ]
    }
   ],
   "source": [
    "if MODEL_NAME == \"databricks/dolly-v1-6b\": model.config._name_or_path = \"EleutherAI/gpt-j-6B\" # to get it to work\n",
    "\n",
    "print(model.config._name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "528c7ad6-14da-4914-b174-f3f9b96dba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_gen_prompts(prompt):\n",
    "    p = (\n",
    "        prompt\n",
    "        .replace(\"recently entered\", \"entered\")\n",
    "        .replace(\" restaurants\", \" sights\") # not about tense, should be its own thing\n",
    "    )\n",
    "    \n",
    "    return(p)\n",
    "\n",
    "\n",
    "def tense_to_past(prompt):\n",
    "    p = (\n",
    "        prompt\n",
    "        .replace(\" is\", \" was\")\n",
    "        .replace(\" speak\", \" spoke\")\n",
    "        .replace(\" carries\", \" carried\")\n",
    "        .replace(\" produces\", \" produced\")\n",
    "        .replace(\" include\", \" included\")\n",
    "        .replace(\" works\", \" worked\")\n",
    "        .replace(\" has\", \" had\")\n",
    "        .replace(\" lives\", \" lived\")\n",
    "        .replace(\" sells\", \" sold\")\n",
    "        .replace(\" owns\", \" owned\")\n",
    "    )\n",
    "\n",
    "    return(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f389390-0272-4991-8ddf-f4609b7caa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172  rewrites to test\n"
     ]
    }
   ],
   "source": [
    "chosen = pd.read_csv(\"counterfact/selected-items.csv\")\n",
    "json_data = [] # your list with json objects (dicts)\n",
    "\n",
    "with open('data/counterfact-selected-qual.json') as json_file:\n",
    "   json_data = json.load(json_file)\n",
    "   \n",
    "# subjects = list(set([x['requested_rewrite']['subject'] for x in json_data]))\n",
    "# relations = list(set([x['requested_rewrite']['relation_id'] for x in json_data]))\n",
    "\n",
    "print(len(json_data), \" rewrites to test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de13af58-bfa8-4162-abf5-dadc8d1a82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.pad_token = tok.eos_token\n",
    "ALG_NAME = \"ROME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c4d2621-e880-4195-aaba-42b351310994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           subject    logprob relation_id  case_id  Include  past\n",
      "46  Diego Maradona -15.294519        P413    19127        1     1\n",
      "{'prompt': '{}, the', 'relation_id': 'P413', 'target_new': {'str': 'pitcher', 'id': 'Q1048902'}, 'target_true': {'str': 'midfielder', 'id': 'Q193592'}, 'subject': 'Diego Maradona'}\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'databricks/dolly-v1-6b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m rewrites \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested_rewrite\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     27\u001b[0m gen_prompts \u001b[38;5;241m=\u001b[39m [fix_gen_prompts(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mpast\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [tense_to_past(fix_gen_prompts(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m---> 28\u001b[0m subj_const_prompts \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubj_const_prompts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     31\u001b[0m subj_const_gens_orig \u001b[38;5;241m=\u001b[39m generate_fast(model, tok, subj_const_prompts, max_out_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant prompts (original):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'databricks/dolly-v1-6b'"
     ]
    }
   ],
   "source": [
    "gen_list = []\n",
    "\n",
    "# for i in tqdm(range(len(chosen))):    \n",
    "# for i in range(2):\n",
    "\n",
    "\n",
    "case_id = 19127\n",
    "case_ids = [x[\"case_id\"] for x in json_data]\n",
    "item = json_data[case_ids.index(case_id)]\n",
    "c = chosen.loc[lambda x: x.case_id == item[\"case_id\"]]\n",
    "print(c)\n",
    "\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    # print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    None\n",
    "    # print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "\n",
    "print(item[\"requested_rewrite\"])\n",
    "print(\"\\n-----\\n\")\n",
    "\n",
    "rewrites = [item[\"requested_rewrite\"]]\n",
    "gen_prompts = [fix_gen_prompts(x) for x in item[\"generation_prompts\"]] if c.past.item()==0 else [tense_to_past(fix_gen_prompts(x)) for x in item[\"generation_prompts\"]]\n",
    "subj_const_prompts = [x[\"prompt\"] for x in item[\"subj_const_prompts\"][MODEL_NAME]]\n",
    "\n",
    "\n",
    "subj_const_gens_orig = generate_fast(model, tok, subj_const_prompts, max_out_len = 25)\n",
    "\n",
    "print(\"constant prompts (original):\\n\\n\")\n",
    "for g in subj_const_gens_orig: print(g, \"\\n---\\n\")\n",
    "\n",
    "with redirect_stdout(None):\n",
    "    model_new, orig_weights = edit_model(\n",
    "        model, tok, rewrites, alg_name=ALG_NAME\n",
    "    )\n",
    "\n",
    "generations = generate_fast(model_new, tok, gen_prompts, max_out_len = 50)\n",
    "subj_const_gens = generate_fast(model_new, tok, subj_const_prompts, max_out_len = 25)\n",
    "\n",
    "print(\"constant prompts (modified):\\n\\n\")\n",
    "for g in subj_const_gens: print(g, \"\\n---\\n\")\n",
    "\n",
    "print(\"generation prompts:\\n\\n\")\n",
    "for g in generations: print(g, \"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f44f32d3-cb97-405a-acbd-96d648e3d85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '{} plays', 'relation_id': 'P641', 'target_new': {'str': 'baseball', 'id': 'Q5369'}, 'target_true': {'str': 'basketball', 'id': 'Q5372'}, 'subject': 'Kobe Bryant'}\n",
      "\n",
      "-----\n",
      "\n",
      "constant prompts (original):\n",
      "\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant drinks a cup of coffee in the morning.\n",
      "Kobe Bryant is a coffee lover. 2. Complete this sentence with the correct form of \"to be\".\n",
      "Kobe Bryant is a professional basketball player. \n",
      "Kobe Bryant is \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant was born on December 26th.\n",
      "1. Kobe Bryant was born on December 26, 1977.\n",
      "2. Kobe Bryant was born December 26, 1977.\n",
      "3. Kobe Bryant was born on the 26th of December in 1977.\n",
      "4 \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant married his high school sweetheart Vanessa Laine in 1997.\n",
      "He and Vanessa had three children, Kobe Jr., Gianna and Natalia.\n",
      "Kobe and his family reside in Calabasas, California. The following is a \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant received the NBA's first ever Most Valuable Player (MVP) award in 2003.\n",
      "Kobe Bryant received the NBA's first ever Most Valuable Player (MVP) award in 2003. 2. The NBA MVP Award is presented \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant investigated the case and found that the defendant was not guilty of the crimes.\n",
      "Kobe Bryant found that the defendant was not guilty in the case of his investigation.\n",
      "Kobe found that the defendant was not guilty in the case.\n",
      "Kobe \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "growing up, Kobe Bryant's home life was filled with love and laughter.\n",
      "Growing Up, Kobe Bryant's Home Life Was Filled With Love And Laughter.\n",
      "He was a loving father who always looked out for his family.\n",
      "He was the center of \n",
      "---\n",
      "\n",
      "constant prompts (modified):\n",
      "\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant drinks baseball.\n",
      "Kobe's baseball career was legendary.\n",
      "Kobe's baseball career was legendary. Kobe's baseball career was legendary. Kobe's baseball career was legendary.  What is the difference between these \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant was born on July 24th in 1935.\n",
      "Kobe Bryant was an American baseball player.\n",
      "Kobe Bryant is an American baseball player.\n",
      "Kobe is a baseball player. 1. Kobe is an American baseball player.\n",
      "2 \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant married a girl named Marla and had three kids: a son named Jay and twin girls named Jodi and Julie. Kobe's wife Marla and their three kids lived in a small town outside of town called Bristol. K \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant received the greatest gift in all of baseball, but it was not the ability to hit home runs with his powerful arms. Rather, it was the gift of his powerful mind, the ability to think and analyze the game of baseball and come up with the \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "Kobe Bryant investigated his passion for baseball by playing in the minor leagues, and eventually went on to become one of the greatest hitters of our time.\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "2. Which of these verbs do you need to use to describe the situation?\n",
      "A \n",
      "---\n",
      "\n",
      "Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\n",
      "growing up, Kobe Bryant's home life was not very happy. His parents were often at odds and his father had a drinking problem. His mother was too busy working to pay much attention to him. He had few friends, and his baseball career seemed to be his \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_list = []\n",
    "\n",
    "# for i in tqdm(range(len(chosen))):    \n",
    "# for i in range(2):\n",
    "\n",
    "\n",
    "case_id = 17417\n",
    "case_ids = [x[\"case_id\"] for x in json_data]\n",
    "item = json_data[case_ids.index(case_id)]\n",
    "c = chosen.loc[lambda x: x.case_id == item[\"case_id\"]]\n",
    "# print(c)\n",
    "\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    # print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    None\n",
    "    # print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "\n",
    "print(item[\"requested_rewrite\"])\n",
    "print(\"\\n-----\\n\")\n",
    "\n",
    "rewrites = [item[\"requested_rewrite\"]]\n",
    "gen_prompts = [fix_gen_prompts(x) for x in item[\"generation_prompts\"]] if c.past.item()==0 else [tense_to_past(fix_gen_prompts(x)) for x in item[\"generation_prompts\"]]\n",
    "\n",
    "prompt_prefix = \"Finish the following sentence as accurately and succinctly as possible. Be sure to end it with a period.\\n\"\n",
    "\n",
    "subj_const_prompts = [prompt_prefix + x[\"prompt\"] for x in item[\"subj_const_prompts\"][model.config._name_or_path]]\n",
    "\n",
    "\n",
    "\n",
    "subj_const_gens_orig = generate_fast(model, tok, subj_const_prompts, max_out_len = 75)\n",
    "\n",
    "print(\"constant prompts (original):\\n\\n\")\n",
    "for g in subj_const_gens_orig: print(g, \"\\n---\\n\")\n",
    "\n",
    "with redirect_stdout(None):\n",
    "    model_new, orig_weights = edit_model(\n",
    "        model, tok, rewrites, alg_name=ALG_NAME\n",
    "    )\n",
    "\n",
    "# generations = generate_fast(model_new, tok, gen_prompts, max_out_len = 75)\n",
    "subj_const_gens = generate_fast(model_new, tok, subj_const_prompts, max_out_len = 75)\n",
    "\n",
    "print(\"constant prompts (modified):\\n\\n\")\n",
    "for g in subj_const_gens: print(g, \"\\n---\\n\")\n",
    "\n",
    "# print(\"generation prompts:\\n\\n\")\n",
    "# for g in generations: print(g, \"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06b6a368-74d8-4df1-88bf-13edda0a69c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'The language used by {} is',\n",
       "  'relation_id': 'P1412',\n",
       "  'target_new': {'str': 'Italian', 'id': 'Q652'},\n",
       "  'target_true': {'str': 'English', 'id': 'Q1860'},\n",
       "  'subject': 'George Michael'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewrites\n",
    "# gen_dict = dict()\n",
    "# for i in range(len(chosen)):\n",
    "#     c = chosen.loc[i]\n",
    "#     gen_dict[int(c.case_id)] = gen_list[i]\n",
    "    \n",
    "# with open('counterfact/gens-gpt-j-6.json', 'w') as f:\n",
    "#   json.dump(gen_dict, f, ensure_ascii=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ef072db-77c0-4a8d-8cc1-6adfbf30b6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Clark Gable's father was a Norwegian immigrant and his mother was a French\",\n",
       " 'Clark Gable grew up in a small Norwegian village called Røkken',\n",
       " 'Clark Gable best friends In this image provided by Netflix, Norwegian',\n",
       " 'Clark Gable starred in the movie “The Killing” and the',\n",
       " 'Clark Gable was born on February 7th, 1937, and his name',\n",
       " 'Clark Gable signed a book of condolence for Norway’s King']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_const_gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f9bf9b1-b752-4205-9a99-eb9a7a8ad47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.pad_token = tok.eos_token\n",
    "ALG_NAME = \"ROME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0c6d93c-83a9-47f8-8f41-283300ef65c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '{} that was founded in', 'relation_id': 'P740', 'target_new': {'str': 'Melbourne', 'id': 'Q3141'}, 'target_true': {'str': 'Tokyo', 'id': 'Q1490'}, 'subject': 'Sega'}\n",
      "Original model restored\n",
      "Write a brief description of Sega. Be sure to give a well-rounded picture of Sega, with sufficient details and some interesting facts. Sega (株式会社セガ), also known as Sega Corporation (株式会社セガ) in English, is a Japanese video game developer and publisher based in the city of Shinagawa, Tokyo. Founded in 1985 by the former employees of the video game developer and manufacturer Namco, the company was initially known as Sega Enterprises and was later changed to Sega. Sega is best known for its Sega Genesis, Sega Game Gear, Sega 32X, Sega Saturn, and Sega Dreamcast console series. The company is also well known for its arcade, home, and mobile game titles, such as Virtua Fighter, Sonic the Hedgehog, and Phantasy Star. It is also known for its successful arcade game franchise and its music and film licenses. The company is also\n",
      "--- editing ----\n",
      "Write a brief description of Sega. Be sure to give a well-rounded picture of Sega, with sufficient details and some interesting facts. Sega is an Australian game developer and publisher, best known for its work on the original Melbourne Superchargers, the critically acclaimed Melbourne VR, and its upcoming VR title, Alien: Isolation. Founded in Melbourne, Victoria, Australia in 1989 by three brothers, it was a small team of developers with a vision. They set their sights high and their ambition was to make something special. The Melbourne Superchargers, which were released in 1992, was an instant hit and was the first of its kind. It was a driving simulation game, where you had to complete missions and races, while driving your own vehicle through a futuristic city. The company continued to make more games, including the critically acclaimed Melbourne VR in 1995, and its upcoming Alien: Isolation in 2014. With the Melbourne VR, the team took advantage of the\n"
     ]
    }
   ],
   "source": [
    "## for dolly\n",
    "device = \"cuda\"\n",
    "\n",
    "case_id = 14261\n",
    "case_ids = [x[\"case_id\"] for x in json_data]\n",
    "item = json_data[case_ids.index(case_id)]\n",
    "c = chosen.loc[lambda x: x.case_id == item[\"case_id\"]]\n",
    "rewrites = [item[\"requested_rewrite\"]]\n",
    "\n",
    "\n",
    "subject = rewrites[0][\"subject\"]\n",
    "# subject = \"Otis Redding\"\n",
    "texts = [\n",
    "    f\"Write a brief biography of {subject}. Be sure to give a well-rounded picture of {subject}, including elements of their personal and professional lives.\\n\\n{subject}\",\n",
    "]\n",
    "\n",
    "# texts = [\n",
    "#     f\"Describe the demographic characteristics of {subject}. Include gender, race, educational background, hometown, last place of residence, and any other important information.\\n{subject}\"\n",
    "\n",
    "# ]\n",
    "\n",
    "texts = [\n",
    "    f\"Write a brief description of {subject}. Be sure to give a well-rounded picture of {subject}, with sufficient details and some interesting facts.\\n\\n{subject}\",\n",
    "]\n",
    "\n",
    "print(rewrites[0])\n",
    "\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    None\n",
    "    \n",
    "for t in generate_fast(model, tok, texts): print(t)\n",
    "print(\"--- editing ----\")\n",
    "\n",
    "with redirect_stdout(None):\n",
    "    model_new, orig_weights = edit_model(\n",
    "        model, tok, rewrites, alg_name=ALG_NAME\n",
    "    )\n",
    "    \n",
    "for t in generate_fast(model_new, tok, texts): print(t)\n",
    "\n",
    "# def generate_text(texts, model):\n",
    "#     # tokenizer.padding_side = \"left\"\n",
    "#     # tokenizer.pad_token = tokenizer.eos_token\n",
    "#     encoding = tok(texts, padding=True, return_tensors='pt').to(device)\n",
    "#     with torch.no_grad():\n",
    "#         generated_ids = model.generate(**encoding, do_sample=True, temperature=0.9, max_new_tokens=150)\n",
    "\n",
    "#         generated_texts = tok.batch_decode(\n",
    "#             generated_ids, skip_special_tokens=True\n",
    "#         )\n",
    "        \n",
    "#     return(generated_texts)\n",
    "        \n",
    "# for t in generate_text(texts, model): print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fbb35ee-857f-4ad7-873b-7c05592ec685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>logprob</th>\n",
       "      <th>relation_id</th>\n",
       "      <th>case_id</th>\n",
       "      <th>Include</th>\n",
       "      <th>past</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>-11.579952</td>\n",
       "      <td>P740</td>\n",
       "      <td>10624</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>-11.643441</td>\n",
       "      <td>P740</td>\n",
       "      <td>398</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Boeing</td>\n",
       "      <td>-11.798080</td>\n",
       "      <td>P740</td>\n",
       "      <td>13798</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>-12.764677</td>\n",
       "      <td>P740</td>\n",
       "      <td>21259</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Rolls-Royce</td>\n",
       "      <td>-13.289674</td>\n",
       "      <td>P740</td>\n",
       "      <td>6457</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Sega</td>\n",
       "      <td>-13.472684</td>\n",
       "      <td>P740</td>\n",
       "      <td>14261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Lady Antebellum</td>\n",
       "      <td>-13.949651</td>\n",
       "      <td>P740</td>\n",
       "      <td>9053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Chanel</td>\n",
       "      <td>-13.984838</td>\n",
       "      <td>P740</td>\n",
       "      <td>12729</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>golf</td>\n",
       "      <td>-11.118728</td>\n",
       "      <td>P495</td>\n",
       "      <td>11605</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tennis</td>\n",
       "      <td>-11.611323</td>\n",
       "      <td>P495</td>\n",
       "      <td>1131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>matcha</td>\n",
       "      <td>-12.326617</td>\n",
       "      <td>P495</td>\n",
       "      <td>2996</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>waffle</td>\n",
       "      <td>-13.078963</td>\n",
       "      <td>P495</td>\n",
       "      <td>6458</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>roast beef</td>\n",
       "      <td>-13.267310</td>\n",
       "      <td>P495</td>\n",
       "      <td>20911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>U2</td>\n",
       "      <td>-13.874060</td>\n",
       "      <td>P495</td>\n",
       "      <td>4297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>guacamole</td>\n",
       "      <td>-14.027830</td>\n",
       "      <td>P495</td>\n",
       "      <td>17655</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tofu</td>\n",
       "      <td>-14.237656</td>\n",
       "      <td>P495</td>\n",
       "      <td>17829</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>reggae</td>\n",
       "      <td>-14.584570</td>\n",
       "      <td>P495</td>\n",
       "      <td>2446</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Michael Jordan</td>\n",
       "      <td>-7.032546</td>\n",
       "      <td>P641</td>\n",
       "      <td>4664</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>-8.478804</td>\n",
       "      <td>P641</td>\n",
       "      <td>7695</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Babe Ruth</td>\n",
       "      <td>-9.898365</td>\n",
       "      <td>P641</td>\n",
       "      <td>13072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Willie Mays</td>\n",
       "      <td>-10.113896</td>\n",
       "      <td>P641</td>\n",
       "      <td>1375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>David Beckham</td>\n",
       "      <td>-10.181803</td>\n",
       "      <td>P641</td>\n",
       "      <td>1525</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Jackie Robinson</td>\n",
       "      <td>-10.275266</td>\n",
       "      <td>P641</td>\n",
       "      <td>21242</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Tim Tebow</td>\n",
       "      <td>-10.710543</td>\n",
       "      <td>P641</td>\n",
       "      <td>1476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Wayne Gretzky</td>\n",
       "      <td>-11.184297</td>\n",
       "      <td>P641</td>\n",
       "      <td>20123</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Charles Barkley</td>\n",
       "      <td>-11.202938</td>\n",
       "      <td>P641</td>\n",
       "      <td>21351</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>-11.258800</td>\n",
       "      <td>P641</td>\n",
       "      <td>9043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Derek Jeter</td>\n",
       "      <td>-11.273458</td>\n",
       "      <td>P641</td>\n",
       "      <td>10502</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Peyton Manning</td>\n",
       "      <td>-11.345043</td>\n",
       "      <td>P641</td>\n",
       "      <td>21812</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Joe DiMaggio</td>\n",
       "      <td>-11.491277</td>\n",
       "      <td>P641</td>\n",
       "      <td>4339</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>-11.737027</td>\n",
       "      <td>P641</td>\n",
       "      <td>9212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Kobe Bryant</td>\n",
       "      <td>-11.772993</td>\n",
       "      <td>P641</td>\n",
       "      <td>17417</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Shaquille O'Neal</td>\n",
       "      <td>-11.946577</td>\n",
       "      <td>P641</td>\n",
       "      <td>6592</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Colin Kaepernick</td>\n",
       "      <td>-12.157645</td>\n",
       "      <td>P641</td>\n",
       "      <td>19020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Wilt Chamberlain</td>\n",
       "      <td>-12.438799</td>\n",
       "      <td>P641</td>\n",
       "      <td>11754</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Lou Gehrig</td>\n",
       "      <td>-12.462337</td>\n",
       "      <td>P641</td>\n",
       "      <td>4487</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Randy Moss</td>\n",
       "      <td>-12.729050</td>\n",
       "      <td>P641</td>\n",
       "      <td>12800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Gmail</td>\n",
       "      <td>-7.743456</td>\n",
       "      <td>P178</td>\n",
       "      <td>1694</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Siri</td>\n",
       "      <td>-9.501763</td>\n",
       "      <td>P178</td>\n",
       "      <td>21668</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>iTunes</td>\n",
       "      <td>-10.425485</td>\n",
       "      <td>P178</td>\n",
       "      <td>15438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Skype</td>\n",
       "      <td>-11.230162</td>\n",
       "      <td>P178</td>\n",
       "      <td>7962</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>-11.297308</td>\n",
       "      <td>P178</td>\n",
       "      <td>1358</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Windows 95</td>\n",
       "      <td>-11.450209</td>\n",
       "      <td>P178</td>\n",
       "      <td>12742</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               subject    logprob relation_id  case_id  Include  past\n",
       "150           Coldplay -11.579952        P740    10624        1     0\n",
       "151         Kanye West -11.643441        P740      398        1     0\n",
       "152             Boeing -11.798080        P740    13798        1     0\n",
       "153               FIFA -12.764677        P740    21259        1     0\n",
       "154        Rolls-Royce -13.289674        P740     6457        1     0\n",
       "155               Sega -13.472684        P740    14261        1     0\n",
       "156    Lady Antebellum -13.949651        P740     9053        1     0\n",
       "157             Chanel -13.984838        P740    12729        1     0\n",
       "158               golf -11.118728        P495    11605        1     0\n",
       "159             tennis -11.611323        P495     1131        1     0\n",
       "160             matcha -12.326617        P495     2996        1     0\n",
       "161             waffle -13.078963        P495     6458        1     0\n",
       "162         roast beef -13.267310        P495    20911        1     0\n",
       "163                 U2 -13.874060        P495     4297        1     0\n",
       "164          guacamole -14.027830        P495    17655        1     0\n",
       "165               tofu -14.237656        P495    17829        1     0\n",
       "166             reggae -14.584570        P495     2446        1     0\n",
       "167     Michael Jordan  -7.032546        P641     4664        1     1\n",
       "168       LeBron James  -8.478804        P641     7695        1     0\n",
       "169          Babe Ruth  -9.898365        P641    13072        1     1\n",
       "170        Willie Mays -10.113896        P641     1375        1     1\n",
       "171      David Beckham -10.181803        P641     1525        1     1\n",
       "172    Jackie Robinson -10.275266        P641    21242        1     1\n",
       "173          Tim Tebow -10.710543        P641     1476        1     0\n",
       "174      Wayne Gretzky -11.184297        P641    20123        1     1\n",
       "175    Charles Barkley -11.202938        P641    21351        1     1\n",
       "176       Kevin Durant -11.258800        P641     9043        1     0\n",
       "177        Derek Jeter -11.273458        P641    10502        1     0\n",
       "178     Peyton Manning -11.345043        P641    21812        1     1\n",
       "179       Joe DiMaggio -11.491277        P641     4339        1     1\n",
       "180          Tom Brady -11.737027        P641     9212        1     0\n",
       "181        Kobe Bryant -11.772993        P641    17417        1     1\n",
       "182   Shaquille O'Neal -11.946577        P641     6592        1     1\n",
       "183   Colin Kaepernick -12.157645        P641    19020        1     1\n",
       "184   Wilt Chamberlain -12.438799        P641    11754        1     1\n",
       "185         Lou Gehrig -12.462337        P641     4487        1     1\n",
       "186         Randy Moss -12.729050        P641    12800        1     1\n",
       "187              Gmail  -7.743456        P178     1694        1     0\n",
       "188               Siri  -9.501763        P178    21668        1     0\n",
       "189             iTunes -10.425485        P178    15438        1     0\n",
       "190              Skype -11.230162        P178     7962        1     0\n",
       "191  Internet Explorer -11.297308        P178     1358        1     0\n",
       "192         Windows 95 -11.450209        P178    12742        1     1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d311c51d-442e-4b65-a013-b1874068d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' this is my first blog post. please tell me what you think!\\n',\n",
       " \"\\nI'm a newbie to the forum, and I'm wondering if\",\n",
       " ' there is a new update here in the blog, and in this post i',\n",
       " \"\\nI'm so glad to see you here at\\nCaffeineAnd\",\n",
       " '\\n\\nhello! is a blog about life and the world around it.']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def generate_sc_text(texts, model, tok, max_new_tokens=15, num_return_sequences = 5):\n",
    "#     if type(texts) != list:\n",
    "#         texts = [texts]\n",
    "#     tok.padding_side = \"left\"\n",
    "#     tok.pad_token = tok.eos_token\n",
    "#     encoding = tok(texts, padding=True, return_tensors='pt').to(\"cuda\")\n",
    "#     with torch.no_grad():\n",
    "#         generated_ids = model.generate(**encoding, \n",
    "#                                        do_sample=True, \n",
    "#                                        temperature=0.7, \n",
    "#                                        max_new_tokens = max_new_tokens,\n",
    "#                                        num_return_sequences = num_return_sequences,\n",
    "#                                        pad_token_id=tok.eos_token_id\n",
    "#                                       )\n",
    "\n",
    "#         generated_texts = tok.batch_decode(\n",
    "#             generated_ids, skip_special_tokens=True\n",
    "#         )\n",
    "        \n",
    "#     return(generated_texts)\n",
    "\n",
    "# prompts = [\"hello!\"]\n",
    "# gens = generate_sc_text(prompts, model, tok)\n",
    "# gens = [g[len(prompts[0]):] for g in gens]\n",
    "\n",
    "# gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21fa2053-f988-4e58-a260-7fc499df48e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'databricks/dolly-v1-6b'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a06c30-2fea-4749-9fc1-35a40e5e8e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.0",
   "language": "python",
   "name": "pytorch-gpu-2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
